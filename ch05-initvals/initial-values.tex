\chapter{Initialization of Parametric Estimators}
\label{sec:initvals}
\myEpigraph{Everything starts somewhere, though many physicists disagree. But people have always been dimly aware of the problem with the start of things. They wonder how the snowplough driver gets to work, or how the makers of dictionaries look up the spelling of words.}{Terry Pratchett}{Hogfather}
\gdef\thisDir{ch05-initvals}
\tikzsetfigurename{ch05fig}
\glsresetall
\researchBasedOn{Geerardyn2015TIM}

\section{Introduction}
\label{sec:initial-values:introd}
The task of interpreting measurement data from dynamic systems often involves the estimation of a \gls{TF}. 
Typical measurement techniques and identification strategies of  \glspl{TF} or \glspl{FRF} are presented in~\citep{Schoukens1998,Schoukens2006LPM,Guillaume1996,Broersen1995,Pintelon2010LPM1,Antoni2007FRF}.
Application of these methods to real devices and systems is well-represented in the literature, e.g. \citep{Lim2010,Robinson1990,Behjat2010}.

Parametric identification of \gls{LTI} systems from either input/output data or non-parametric frequency response data, has been well developed as evidenced by published literature~\citep{Pintelon2012,Ljung1999,Schoukens1999,Pintelon1998,Soderstrom1989,Goodwin1977,Brillinger1981,Sanathanan1963,McKelvey2002,Peeters2004}.
Many of such parametric identification algorithms, however, require solving non-linear or non-convex optimization problems.
This often involves an iterative algorithm to produce the optimal model.
 The resulting model, however, depends on which initial estimates are used to start up the optimization process: typically one can end up in local minima, leading to models of sub-optimal quality.
 Hence, good initial estimates are essential to obtain a high quality model estimate.
 In this chapter, the \gls{MLE} is used as a proxy for any parametric transfer function estimator, since the \gls{MLE} is commonly used and has desirable properties such as efficiency and consistency.
 Numerous other parametric identification techniques are devoted to the development of parametric plants $G(q^{-1},\theta)$ and parametric noise models  $H(q^{-1},\theta)$, where  $\theta$ is the model parameters vector \citep{Ljung1999,Soderstrom1989,Pintelon2012}.
 Since the initial value generation methods are not specifically tailored towards the \gls{MLE}, other parametric identification frameworks are likely to benefit from these improved starting values as well.
 Hence, the presented approach is complementary to initialization schemes such as the work of~\citet{vanHerpen2014} that focuses on improving the optimization algorithm, rather than the starting values.

 In the perspective of developing identification tools that require minimal user interaction, it is important that good initial estimates are produced for a wide variety of systems and experimental settings; i.e. to increase the probability of the optimization algorithm to produce good estimates, or preferably even the global optimum.
 However, when noisy input-output measurements are to be processed, the presence of noise obstructs a clear view of the actual system behavior, especially for poor \glspl{SNR}.
 Such problems can be mitigated using non-parametric techniques: the presence of noise is typically reduced by averaging multiple measurements or by using more advanced smoothing techniques.

The main aim and contribution of this chapter is to demonstrate that smoothing a measured \gls{FRF} non-parametrically, helps to avoid local optima during the parametric estimation of the \gls{MLE} of a transfer function, using classical (deterministic) optimization algorithms.
Hence, such techniques make it possible to increase the ``success rate'' (i.e. the probability that a good model, or even the global optimum, is obtained) of such a system identification step considerably.

In particular, two different smoothing techniques:
\begin{itemize}
 \item the time-truncated \gls{LPM}~\citep{Lumori2014TIM}, and
 \item the \gls{RFIR}~\citep{Pillonetto2010,Chen2012}
\end{itemize}
are tested for different \glspl{SNR} and different measurement record lengths of the input/output data of a few \gls{SISO} \gls{LTI} systems.
These are compared with the existing initialization schemes, namely: (i) the \gls{GTLS}, and (ii) the \gls{BTLS}.

\paragraph{Outline}
The rest of the chapter is structured as follows. 
\secref{sec:initial-values:ProbForm} covers the problem formulation. 
\secref{sec:initial-values:MethodEg} presents the methodology for obtaining the initial estimates, and their influence on the success rate of the \gls{MLE}. 
This is followed by \secref{sec:initial-values:Demo} and \secref{sec:initial-values:ExpMeas}, which are demonstrations of the improved initial estimates on simulation and experimental data, respectively.
In \secref{sec:initial-values:Generality} the generality of the results is investigated briefly.
The computational effort and recommendations for practical implementations are given in \secref{sec:initvals:computation}.
Ultimately, concluding remarks are presented in \secref{sec:initial-values:Conclusion}.

\section{Problem Formulation}
\label{sec:initial-values:ProbForm}

In this section, the assumptions on the system and the noise are presented, together with the associated MLE (formulated in the frequency domain), which turns out to be a non-convex function in the parameters, requiring initial estimates. The procedure for obtaining the initial estimates is elaborated in the subsequent sections.

\subsection{System Framework and Model}
\figref{fig:oesetup} depicts a schematic of the output error framework for  a generalized (single- or multiple-order) resonating, dynamic \gls{LTI} discrete-time \gls{SISO} system, subjected to a known white random noise input. 
The full model of the system is
\begin{equation}
y(t)=\true{G}(q^{-1})\true{u}(t)+\true{H}(q^{-1})e(t)
\label{eq:initial-values:OE:TD}
\end{equation}
where $\true{G}(q^{-1})$ represents the dynamics of the system to be estimated, $\true{u}(t)$ is the input signal, $v(t)= \true{H}(q^{-1})e(t)$ is the noise source at the output, $\true{H}(q^{-1})$ is the noise dynamics, 
$e(t)$ is white Gaussian noise, and $q^{-m}$ is the backwards shift operator ($q^{-m}x(t)$ = $x(t-mT_{\mathrm{s}})$  with $m$ a positive integer and $T_{\mathrm{s}}$ the sampling time).
We only treat the discrete-time case (i.e. $t = n \cdot T_{\mathrm{s}}$ for integer values of $n$) theoretically in this chapter.
However, the generalization to continuous time is straightforward~\citep[Chapter 6]{Pintelon2012} and has been demonstrated in Section~\ref{sec:initial-values:ExpMeas}.

\begin{figure}[tbh]
\centering
\input{\thisDir/figs/oesetup.tikz}
\caption[Output-error set-up.]{SISO LTI discrete-time system in an output error setup.}
\label{fig:oesetup}
\end{figure}

In this chapter we assume that the output signal is disturbed by random noise, resulting in noisy error-prone data.
For the simulations, white noise is used ($\true{H} = 1$ and $e(t) = v(t)$).
It is also possible to apply the estimation procedure in this chapter to a system that is disturbed by colored noise, as will be demonstrated in \secref{sec:initial-values:ExpMeas}. 

With reference to equation \eqref{eq:initial-values:OE:TD}, the relation between the noiseless input and the output signals ($v(t)= 0$) is assumed to be of the form
\begin{equation}
    A(q^{-1}) \true{y}(t) = B(q^{-1}) \true{u}(t) \quad \forall t \in n \Ts{}  \text{ with }  n \in \IntegerNumbers
\label{ABpolys}
\end{equation}
where $A$ and $B$ are polynomials in $q^{-1}$. 
Thus, it follows from equation \eqref{eq:initial-values:OE:TD} that
\begin{equation}
    \true{G}(q^{-1})= \frac{B(q^{-1})}{A(q^{-1})}
    \text{.}
\end{equation}

From~\citet[Section 6.3.2.]{Pintelon2012}, in the frequency domain, and for the \glspl{DFT} of the windowed signals, equation \eqref{ABpolys} is of the form
\begin{align}
A(e^{-j\omega_k})\true{Y}(k) = B(e^{-j\omega_k})\true{U}(k) + T(e^{-j\omega_k})
\label{DFTspectra}
\end{align}
with $q^{-1}$ sampled in  $q_k^{-1} = e^{-j\omega_k}$, where $\omega_k = \frac{2\pi k}{N}$ are the \gls{DFT} frequencies, and $T$ is a polynomial of order $\max(N_a,N_b) - 1$, which depends on the difference between the initial and end conditions of the filters $\true{G}$ and $\true{H}$ during the measurement record.

\begin{remark}
The knowledge of the true model orders makes the analysis of the smoothers easier to carry out as we thus avoid extra calculation time required to perform model selection.
However, these smoothers can be used in conjunction with model order selection procedures.
\end{remark}

\begin{assumption}
It is assumed that the orders of the polynomials $A$, $B$ and $T$ are known.
\end{assumption}


\subsection{Parametric Identification Algorithm}\label{sec:initial-values:paramIdentAlgo}

The maximum likelihood estimate of the parameter vector $\theta$  containing the coefficients of the $A$, $B$ and $T$  polynomials is obtained by solving the optimization problem
\begin{equation}
  \hat{\theta} = \arg\min_\theta V(\theta) \text{.}
\end{equation}
Since the noise $v(t)$ is assumed to be Gaussian, $V(\theta)$ accords to the weighted least squares cost function~\citep[Section 9.11]{Pintelon2012}:
\begin{equation}\label{eq:MLEcf}
V(\theta) = \sum_{k=1}^{N/2-1}\frac{|\varepsilon(k,\theta)|^2}{\sigma_\varepsilon^2(k,\theta)}
\end{equation}
for $N$ measurements and when $\varepsilon$ denotes the error in equation \eqref{DFTspectra},  \emph{viz}.:
\begin{align}
\varepsilon(k,\theta) = A(k,\theta)Y(k) - B(k,\theta)U(k) - T(k,\theta)\text{.}
\end{align}
The variance of the error is of the form:
\begin{equation}\label{eq:sigmaEps}
\begin{split}
\sigma_\varepsilon^2(k,\theta) 
  &=  |A(k,\theta)|^2\sigma_Y^2(k) 
   +  |B(k,\theta)|^2\sigma_U^2(k)
  - 2\RealPart \left( A(k,\theta) \overline{B(k,\theta)} \sigma_{YU}(k) \right)
\end{split}
\end{equation}
where $\sigma_Y^2$ is independent of $k$ for white noise, and the input error variance is assumed to be zero, i.e. $\sigma^2_U=0$, and similarly, the covariance $\sigma_{YU} = 0$.
Here, $\overline{B}$ denotes the complex conjugate of $B$.

Consequently, $V(\theta)$ is a non-quadratic function of $\theta$ which, in general, results in a non-convex optimization problem. 
The Levenberg-Marquardt algorithm~\citep{Marquardt1963}, is used to solve this optimization problem deterministically and is shown in~\algoref{alg:initvals:levenberg-marquardt}.
Such an approach requires good initial estimates of $\theta$ to avoid inherent local optima, which is the focus of this chapter.

\begin{algorithm}
\caption{Levenberg-Marquardt~\citep{Marquardt1963},~\citep[Sec. 9.L.4]{Pintelon2012}}
\label{alg:initvals:levenberg-marquardt}
\begin{algorithmic}[1]
  \Require Cost function \eqref{eq:MLEcf} is rewritten as $V(\theta) = \InnerProductSelf{\epsilon(\theta)}$. 
\Function{LevenbergMarquardt}{$\epsilon(\theta),  \theta^{\mathrm{init}}$}
   \State $\atIter[0]{\theta} \gets \theta^{\mathrm{init}}$
   \Comment{$\atIter[i]{X}$ denotes $X$ at iteration $i$.}
   \For{$i$ \textbf{in} $1 \to \infty$}
      \State $U \, \Sigma \, W^{\TT} \gets \code{svd}\left( \frac{\partial \epsilon(\atIter[i-1]{\theta})}{\partial \theta}\right)$ 
        \Comment{Singular value decomposition of Jacobian}
      % \State $
      %                  \text{Denote }\Sigma \equiv 
      %                  \left[ \begin{matrix} 
      %                  \sigma_1         & \deemph{0} & \deemph{\cdots} &           & \deemph{0}      \\
      %                  \deemph{0}      & \sigma_2    &                   &           &                   \\
      %                  \deemph{\vdots} &              & \ddots            &           & \deemph{\vdots} \\
      %                                    &              &                   & \sigma_n &                   \\
      %                   \deemph{0}      &              & \deemph{\cdots} &           & \deemph{0}      
      %                   \end{matrix}\right]
      %                $
      % \State \textbf{if} $i=1$ \textbf{ then} $\lambda \gets \max(\sigma) / 100$
      \If{$\lambda$ is undefined}
        \State $\lambda \gets \max(\Set{\Sigma_{11}, \ldots, \Sigma_{\numel{\theta}\numel{\theta}}})/100$
      \EndIf
      \State $\Sigma_{kk} \gets \frac{\Sigma_{kk}}{(\Sigma_{kk}^2 + \lambda^2)} \quad \forall k \in \Set{1, \ldots, \numel{\theta}}$
      \State $\delta\theta \gets - W  \Sigma^{\TT}  U^{\TT} \epsilon(\atIter[i-1]{\theta})$
      \State $\atIter[i]{\theta} \gets \frac{(\atIter[i-1]{\theta} + \delta\theta) }{ \norm[2]{\atIter[i-1]{\theta} + \delta\theta} }$
      \If{$V(\atIter[i]{\theta}) > V(\atIter[i-1]{\theta})$} \Comment{Current step is a deterioration}
         \State $\atIter[i]{\theta} \gets \atIter[i-1]{\theta}$ \Comment{Restart loop from previous estimate}
          \State $\lambda \gets 10 \lambda$ 
      \Else
          \State $\lambda \gets 0.4 \lambda$
      \EndIf
      \If {$\norm[2]{\delta\theta} < n_{\theta}  \cdot 10^{-6} \norm[2]{\atIter[i]{\theta}}$}
          \State \textbf{return} $\hat{\theta} \gets \atIter[i]{\theta}$
      \EndIf
   \EndFor
\EndFunction
\end{algorithmic}
\end{algorithm}

\begin{remark}
Alternatively, stochastic optimization algorithms~\citep{Spall2012,Press2007} are less likely to get stuck in local optima since such algorithms use randomization either to select initial values or to iterate towards the optimum (or both).
However, due to this random influence, their results are not always exactly reproducible and can incur a huge computational cost compared to `classical' deterministic schemes where only a single or a few initial estimates are used to start the expensive iterative optimization procedure.
Stochastic optimization is not discussed in the remainder of this chapter.
\end{remark}

\section{Methodology}\label{sec:initial-values:MethodEg}
In this section, the considered methods for obtaining the initial estimates of $\theta$ are briefly explained. Then their influence on the success rate of the maximum likelihood estimator is described.
%}

\subsection{Initial Estimates Procedure}\label{sec:init:procedures}
\begin{figure}[p]
  \centering
  \includegraphics[width=\columnwidth]{\thisDir/figs/flowgraph}
  \caption[Flow chart of different initialization procedures.]{Flow chart depicting the different estimation procedures, from left to right: \circledNum{1} an approach using the true model as initial estimate; \circledNum{2} an existing approach using \gls{BTLS} and \gls{GTLS} starting values, and the novel initialization strategies outlined in this chapter (\circledNum{3}, \circledNum{4}) that make use of smoothers to generate improved starting values for the non-convex optimization problem.
  The flow of non-parametric data is depicted by full arrows, with the \gls{FRF} data marked by asterisks. Parametric models are indicated by dashed, unfilled arrows.} 
  \label{fig:flowgraph}
\end{figure}

The ultimate aim is to find initial estimates that are good enough to steer clear of the local optima during the \gls{MLE} optimization process in the parametric identification of each system. 
The requisite procedures for the estimators are as follows, from left to right of the flowchart in \figref{fig:flowgraph}:

\begin{enumerate}
\item \emph{Using the true model ($\true{G}$) as initial estimate}

The estimates from this procedure are for comparison purposes with those from the other procedures. They will be crucial to the computation of the global optimum of the \gls{MLE}.

\item \emph{Quadratic approximations of the \gls{MLE}}

The \gls{GTLS} and the \gls{BTLS} have been presented in \citep{Pintelon1998}. 
These are modifications of equation \eqref{eq:MLEcf}, which still take into account the noise information while retaining the quadratic nature w.r.t. $\theta$. 
These estimators preserve consistency, such that the estimates converge asymptotically to the true parameters for $N\to\infty$. 
Their finite sample behavior, however, is suitable for improvement by the \gls{FRF} smoothing tools as described below.

\item \emph{Local polynomial method (LPM) with truncation}
\disclaimer{The time-truncated \gls{LPM} has been explained in \secref{sec:nonparametric:truncation} in more detail. The pertinent details are repeated here to aid readability.}
A good estimate of the \gls{FRF} of the chosen system can be obtained via the truncated \gls{LPM}, which is summarized as follows~\citep{Lumori2014TIM} and \secref{sec:nonparametric:truncation} of this thesis.
The \gls{LPM} is first applied to estimate the \gls{FRF} from a full input/output data record of the \gls{SISO} system.
The smooth characteristics of both the exact \gls{FRF} $\true{G}$ and the transient term $T$ allow for application of the \gls{LPM}, leading to a smooth \gls{FRF} estimate with the transient and noise suppressed.

  With reference to a detailed exposition in~\citep{Lumori2014TIM} and \chapref{sec:nonparametric}, the \gls{LPM} utilizes local polynomials to approximate the transfer function and transient contribution (in least squares sense) and, thus, smooth $\true{G}$ and $T$ around a central frequency $\omega_{k}$ in a local frequency band $\omega_{k+r}\in\LocalWindow$.
  In this chapter, we limit the notations to quadratic polynomials ($\order{B} = \order{T} = 2$) in a window with half-width $\numel{W}=3$, such that
\begin{subequations}\label{lpmImplQuadG}
\begin{align}
\true{G}(\omega_{k+r})&\approx \hat G_k + g_{1,k} r + g_{2,k}r^2
\\
T(\omega_{k+r})&\approx T(\omega_k)+t_{1,k}r + t_{2,k}r^2
\label{lpmImplQuadT}
\end{align}
\end{subequations}
where $r \in \LocalShifts{k}$ with $\LocalShifts{k} = \{-\numel{W},-\numel{W}+1,\dots,\numel{W}\}$.
In general (see \chapref{sec:nonparametric}), $\numel{W}$, $\order{B}$, and $\order{T}$ are tunable parameters. 

  The \gls{LPM} estimate of the \gls{FRF} at frequency index $k$ is the first estimated local parameter, \emph{viz}:
\begin{equation}
\hat{G}_{\LPM}(\omega_k) = \hat{G}_k
\text{.}
\end{equation}
This procedure is repeated for all $k$ in the frequency band of interest.

\emph{Impulse response truncation}. 
The estimate is smoothed further by truncating its impulse response function $g_{\LPM}(t) = \IDFT \left( \hat{G}_{\LPM}(\omega_k)) \right)$ as originally presented in~\citep{Lumori2014TIM} and \secref{sec:nonparametric:truncation}.

The impulse response is truncated after the time $\truncTime$ where the signal becomes indistinguishable from the noise, i.e.,
\begin{equation}
  g_{\trunc}(t) = 
  \begin{cases}
    g_{\LPM}(t) & t \leq \truncTime \\
    0                              & t \geq \truncTime
  \end{cases}
  \text{.}
\end{equation}

To this end, an estimate of the envelope of impulse response is determined by fitting an exponential function $g_{\mathrm{exp}}(t) = B e^{\beta t}$ to the peaks of $\abs{g_{\LPM}(t)}$ using a linear least-squares approach.
Then, $\truncTime$ is determined as the time instant where this envelope function sinks below the noise level $\sigma_g$ of the impulse response, i.e. 
\begin{equation}
  \truncTime = \min \Set{ t :  g_{\mathrm{exp}}(t) < \gamma \sigma_g  }
  = \beta^{-1} \ln \frac{\gamma \sigma_g}{B}
  \text{,}
\end{equation}
where $\gamma=1$ was used in this chapter for simplicity.
By changing $\gamma$, the user can fine-tune the bias/variance trade-off of the estimated \gls{FRF} $G_{\trunc}(\omega_k) = \DFT \left( g_{\trunc}(t)\right)$ further.
This can lead to a significant improvement over the classical LPM~\citep{Lumori2014TIM}.
 
\item \emph{\Glsfirst{RFIR}}

The \gls{RFIR} method is a special case of the \gls{RARX} method. 

The \gls{RFIR} estimator is formulated in the time domain. 
It estimates the impulse response of a discrete time system as the minimizer of the following regularized least squares objective function:
\begin{align}\label{eq:hRFIRdef}
\hat g_{\RFIR} &= \argmin_{g} \norm[2]{y - g \conv u }^2 + \sigma^2 g^{\TT}P^{-1}g
\end{align}
where $g$ is the vectorized impulse response $g(t)$, with $t = 0,1,\cdots,n_h - 1$, assuming that the impulse response is $n_g$ samples long. 
Furthermore, $g\conv u$ is the convolution of $g$ with the input signal $u$, and $P\in \mathbb{R}^{n_g\times n_g}$ is the kernel matrix~\citep{Chen2012}. 
Note that \eqref{eq:hRFIRdef} is quadratic in $g$, such that $\hat g_{\RFIR}$ can be computed analytically in a single step.
The kernel matrix $P$ embodies prior knowledge on the system to be estimated. 
Here, the \gls{DCkernel}~\citep{Chen2012,Pillonetto2010} is used. 
Specifically, the element at $t_1,t_2$ of $P$ is given by
\begin{equation}
P(\alpha,\beta)_{t_1,t_2} = e^{-\alpha|t_1 - t_2|}e^{-\beta(t_1 + t_2)/2}
\end{equation}
 for $t_1,t_2 \in \set{0,1,\cdots,n_h - 1}$ which makes the estimated impulse response to be an exponentially decaying function of $t$ with decay rate $\beta^{-1}$, and correlation length $\alpha^{-1}$. 
 The latter \emph{hyperparameters} $\alpha$, $\beta$ and $\sigma$ are determined using Empirical Bayes~\citep{Carlin2000,Gelman2014}, i.e. as the maximizers of the \gls{LML} of the measured output signal~\citep{Chen2012}:
\begin{align}
\mathrm{LML}(y) = -y^{\TT}\Sigma(\alpha,\beta,\sigma)^{-1}y - \log |\Sigma(\alpha,\beta,\sigma)| \text{,}
\end{align}
where $\Sigma(\alpha,\beta, \sigma) = \sigma^2 \I + \phi^{\TT}P(\alpha,\beta)\phi$ and $\phi$ is a Toeplitz matrix constructed with $u$. 
This problem is solved using \mcode{fmincon} in \MATLAB.
%TODO: check convexity of this problem

An implementation of the \gls{RFIR} estimator is available as the \mcode{arx} function in the System Identification Toolbox since \MATLAB~2013b with $\mathtt{na} = 0$, $\mathtt{nb} = n_g$, $\mathtt{nk}=0$ and regularization enabled in \mcode{arxOptions}. 
The hyperparameters can be determined via \mcode{arxRegul}.
More information about the \gls{RFIR} estimator can be found in
~\citep{Pillonetto2010,Chen2012}. 
The \gls{DFT} of the obtained regularized estimate of the impulse response $\hat g_{\RFIR}$ of the system yields a smoothed estimate of the \gls{FRF}.
\end{enumerate}

\begin{remark} \label{rem:initvals:orders:RFIR}
In this chapter, all results are obtained using $n_g=200$ since this exceeds the length of most impulse responses used.
However, for general use, the model complexity $n_g$ might need to be increased.
One could use $n_g \approx N$ and rely on regularization to reduce the effective model complexity.
Unfortunately, this scales very poorly for long measurement records as explained in \secref{sec:initvals:computation}.
\end{remark}

\begin{remark}
The \gls{LRM} has also been tried to generate better initial values.
However, given the discussion in \chapref{sec:nonparametric}, it is clear that the \gls{LRM} performs poorly in low \gls{SNR} situations.
The same was apparent from the quick trial we ran on \gls{LRM} starting values.
As such, the use of \gls{LRM} over \gls{LPM} offers no advantage for generating initial estimates in the settings used in this chapter.
\end{remark}


\begin{remark}
Note that methods 3) and 4) result in a non-parametric estimate of the transfer function, represented as the \gls{FRF}. 
A corresponding parametric estimate is obtained as follows. 
A parametric estimator (\gls{GTLS}, \gls{BTLS}, and \gls{MLE}) is invoked, where the input spectrum is considered to be $1$ at all frequencies (Dirac in the time domain), and the output spectrum is set equal to the estimated \gls{FRF} $G_{\bullet}(\omega_k)$, with the transient term $T$ set to zero:
\begin{equation}
  U_{\FRF}(\omega_k) \isdef 1 
  \qquad \text{and} \qquad
  Y_{\FRF}(\omega_k)  \isdef G_{\bullet}(\omega_k)
  \text{.}
\end{equation}
It is important to note that invoking the \gls{GTLS}, \gls{BTLS} and \gls{MLE} on the \glspl{FRF} from methods 3) and 4) will yield a different result from applying the \gls{GTLS}, \gls{BTLS} and \gls{MLE} on the raw data. 
This is because the \glspl{FRF} from 3) and 4) have been smoothed and, thus, have a significantly reduced noise variance, but might be biased slightly.
\end{remark}

\subsection{Success Rates of the Initial Estimates}
The initial estimates described above are then fed to the \gls{MLE} together with the raw data to obtain the final estimates.

Formally, let $\model{\bullet}$ be the final parametric estimate of the system, where the subscript $\bullet$ denotes the methods (from left to right in Fig.~\ref{fig:flowgraph}) when an initial estimate $\model[init]{\bullet}$ is used, \emph{viz}:
\begin{itemize}
    \item $\model{\true{}}$ via the true model $\true{G}$ as an initial estimate,
    \item $\model{exist}$ is obtained via \gls{GTLS} and \gls{BTLS},
    \item $\model{trunc}$ by the use of the \gls{LPM} with truncation as an initial estimate,
    \item $\model{RFIR}$, initialized by means of the \gls{RFIR} method. 
\end{itemize} 

A particular initial estimate is deemed \emph{successful} if the optimization of the \gls{MLE} cost with the raw input-output data inserted in equation~\eqref{eq:MLEcf}, approximately reaches the \emph{best local optimum} when iteration is initiated with the selected initial value/estimate.

\begin{conjecture}\label{conj1}
The true model $\true{G}$ as an initial estimate is the best possible initial estimate one can use for the nonlinear optimization algorithm (the leftmost path in \figref{fig:flowgraph}) and will allow the optimization to converge to the \emph{best local optimum}, i.e. $\model{\true{}}$.
\end{conjecture}
\begin{remark}
The use of $\true{G}$ as an initial estimation not necessarily entails in converging to the global optimum since it is not guaranteed that $\true{G}$ lies within the attraction region of the global optimum.
\end{remark}

From this conjecture, use of the true system as an initial estimate would engender the best final estimate or hopefully even the global optimum.
Since the true system is not really known in practice, this chapter compares the capability of different possible initial estimates to emulate the result that would be obtained by using the true model as an initial estimate. 

The capability is quantified by defining the success rate of the initial estimate as the probability that the identification algorithm reaches the \emph{best local optimum} when the selected initial estimate is used. 
Note that probability in this context should be understood with respect to different realizations of the input signal and disturbing noise.

The success rate $\successRate_{\bullet}$ of an initialization scheme $\bullet$ is defined as the probability that it reaches the \emph{best local optimum}, i.e.
\begin{equation}
\successRate_{\bullet} = 
  \Prob{  \model{\bullet} \approx \model{\true{}}  }
\text{.}
\end{equation}
In practice, and since the iterative algorithm usually does not reach the local optimum precisely, the above definition is implemented practically as
\begin{equation}\label{eq:successrateTol}
\successRate_{\bullet} \isdef \Prob{ \norm[2]{\model{\bullet} - \model{\true{}}} < \absoluteTolerance}
\end{equation}
with $\absoluteTolerance$ a numerical tolerance that will be specified later on.

\begin{remark}
For an automated approach, it is better to define the success rate in terms of relative errors on the transfer function, i.e.
\begin{equation}
\successRate_{\bullet} = \Prob{ \norm[2]{\model{\bullet}-\model{\true{}}} < \relativeTolerance  \norm[2]{\true{G}}}
\text{.}
\end{equation}
\end{remark}
\begin{remark}
In this chapter, the absolute criterion is used.
However, the results are equivalent for a relative criterion when the separation between successful and failed estimates is large since then observed success rate $\successRate$ is not sensitive towards the tolerance $\absoluteTolerance$ (or $\relativeTolerance$) when the tolerance is chosen with care.
Consequently, one can easily determine the equivalent relative tolerance from the absolute one using $\absoluteTolerance = \relativeTolerance \norm[2]{\true{G}}$.
\end{remark}

The $\mathcal{L}_2$ norm used in equation \eqref{eq:successrateTol} is defined~\citep{Skogestad2005} as
\begin{align}
\norm[2]{G(z)} &\isdef \sqrt{\frac{1}{2\pi}\int_0^{2\pi} |G(e^{-j\omega})|^2\ \mathrm{d}\omega}& \text{ for discrete time,}\\
\norm[2]{G(s)} &\isdef \sqrt{\frac{1}{2\pi}\int_{-\infty}^{+\infty} |G(j\omega)|^2\ \mathrm{d}\omega}& \text{ for continuous time}
\end{align}
 which, in practice, is computed by using the adaptive global quadrature algorithm provided by the \MATLAB function \code{integral}.
The success rate in equation \eqref{eq:successrateTol} is estimated via Monte Carlo simulations in \secref{sec:initial-values:CompuSR}.

\begin{remark}
The specific norm that is used in~\eqref{eq:successrateTol} can be adapted to suit the eventual purpose of the models the user wants to obtain.
E.g. in robust control, it often makes sense to rather have a $\Hinf$ norm as in \chapref{sec:hinf} than an $\mathcal{L}_2$ norm.
In this chapter, the $\mathcal{L}_2$ norm has been chosen since this is more closely related to the cost function~\eqref{eq:MLEcf}.
\end{remark}

\section{Demonstration}\label{sec:initial-values:Demo}

\subsection{The System Under Consideration}

Two systems are considered. 
The first, with a quality factor $Q = 6\unit{dB}$, has the transfer function
  \begin{equation}
     \true{G}(z)
    \approx 
    1.74 \cdot 10^{-3}
    \frac{ z^2 + 2 z + 1 }
         { z^2 - 1.93 z + 0.94}
    \text{ i.e. }
    \timeconst \approx 32 \unit{s}
    \text{ for } Q = 6 \unit{dB}
    \label{eq:systemundertest}
    \text{,}
  \end{equation}
where $\timeconst = (\damping \wn)^{-1}$ denotes the time constant of the system (with $\damping$ the damping and $\wn$ the frequency of the dominant pole).
The second system, with a quality factor $Q = 20\unit{dB}$, has the transfer function
  \begin{equation}
    \true{G}(z)
    \approx
    309 \cdot 10^{-6}
            \frac{z^2 + 2 z + 1}
                 {z^2 - 1.98 z + 0.989}
    \text{ i.e. }
    \timeconst \approx 180 \unit{s}
    \text{ for } Q = 20 \unit{dB}
    \label{eq:systundertest-20dB}
    \text{.}
  \end{equation}

Both systems are low-pass Chebyshev filters which have been generated using the \MATLAB command \mcode[mathescape]{cheby1(2, $\,Q$, 0.05)}.
Their transfer functions are shown in \figref{fig:exampleFRF}.
Their inputs are excited by zero mean white Gaussian noise with unit variance, and the outputs are disturbed by different realizations of white Gaussian noise, as in \figref{fig:oesetup}, with a variance $\sigma_v^2$, such that a prescribed \gls{SNR} defined as
\begin{equation}
  \mathrm{SNR} 
    = \frac{\sigma_v}
           {\rms{\true{y}}}
    \approx \frac{\sigma_{v}}
                 {\left\| \true{G} \right\|_2 \rms{\true{u}}}
    =  \frac{\sigma_{v}}
            {\left\| \true{G} \right\|_2}
  \label{eq:SNR-definition}
  \text{.}
\end{equation}
is attained.
$\rms{x} = \sqrt{N^{-1} \sum_t x^2(t)}$ denotes the root-mean-squared value of $x$.

\subsection{Comparison of Successful and Failed Estimates}
 \figref{fig:exampleFRF} depicts the Bode plot of the actual system $\true{G}$, in black and different estimates $\model{exist}$ that may or may not approximate $\model{\true{}}$ well, according to the distance defined by equation \eqref{eq:successrateTol}.
 The systems shown here are drawn randomly from the successes and failures observed in the Monte Carlo simulations, which are discussed later on in this chapter.
 
 It is clear from \figref{fig:exampleFRF} that the successful estimates virtually coincide with the true system. 
 This means that their distances from the true system, e.g. as given by $\norm[2]{\model{\bullet} - \true{G}}$, have small values. 
On the other hand, the `failed' estimates are inaccurate descriptions of the true system. 
It is apparent that their associated distances from the true system are larger by, at least, an order of magnitude than for the successful estimates.
 
 Estimation `failures' can be attributed to the optimization procedure getting stuck in local optima, resulting in very poor estimates of $\true{G}(\omega)$ over broad frequency ranges, as seen in \figref{fig:exampleFRF}. 
 Consequently, such estimates are approximations of $\true{G}$ that are practically worthless for most applications.
 %}


\begin{figure}
  \centering
  \setlength{\figurewidth}{0.8\columnwidth}
  \setlength{\figureheight}{0.6\figurewidth}
  \input{\thisDir/figs/exampleSystems.tikz}
 \caption[Bodeplot of successful ad failed estimates.]{Illustrative Bode plots of a few successful~\legref{leg:example-good-estimate} and `failed'~\legref{leg:example-bad-estimate} estimates $\model{\bullet}$ for both systems $\true{G}$~\legref{leg:example-exact} under test.
 The `failed' estimates are caused by local minima in the cost function.
 Success or failure is determined using the criterion in equation~\eqref{eq:successrateTol}. The $3\unit{dB}$ bandwidth of each system is highlighted~\legref{leg:example-3db-bandwidth}.}
\label{fig:exampleFRF}
\end{figure}

\subsection{Computation of  the Success Rates}
\label{sec:initial-values:CompuSR}

\subsubsection{Simulation}
A Monte Carlo simulation was set up to determine the success rate of the estimator with different initial estimates.
In each run, both the realization of the excitation signal $u$ and the disturbing noise realization ($e$) are varied.
Each run is repeated for the following ranges:
\begin{itemize}
\item of \gls{SNR}: 
              $-20   \unit{dB}$, 
              $-16.7 \unit{dB}$, 
              $-13.3 \unit{dB}$, 
              $-10   \unit{dB}$, 
              $- 7.8 \unit{dB}$, 
              $- 5.6 \unit{dB}$, 
              $- 3.3 \unit{dB}$, 
              $- 1.1 \unit{dB}$, 
              $  1.1 \unit{dB}$, 
              $  3.3 \unit{dB}$, 
              $  5.6 \unit{dB}$, 
              $  7.8 \unit{dB}$, 
              $ 10   \unit{dB}$, 
              $ 13.3 \unit{dB}$, 
              $ 16.7 \unit{dB}$ and
              $ 20   \unit{dB}$
\item of number of samples $N$ is $3\,368\approx 104\timeconst$ or $4\,462\approx 138\timeconst$ for the first system whose quality factor $Q= 6 \unit{dB}$,
\item and of number of samples $N$ is $20\,250\approx 113\timeconst$ or $26\,792\approx 149\timeconst$ for the second system whose quality factor $Q = 20\unit{dB}$.
\end{itemize}
One can, equivalently, express the experiment length as the number $\nBW$ of frequency bins that lie within the $3\unit{dB}$ bandwidth of the system.
The $3\unit{dB}$ bandwidth is defined as the frequency band where the magnitude of the transfer function is, at most, $3\unit{dB}$ below its maximum as indicated in \figref{fig:exampleFRF}.
For both systems, $N$ was chosen such that $\nBW$ is respectively $36$ or $48$.
For each value-pair $(\SNR, \nBW)$ and both systems, $\nMC = 200$  simulations and estimations were performed.
Each individual simulation yields an estimate of the model based on which one can determine whether the estimation was successful or not.
This allows to empirically estimate the success rate $\successRate$ in equation \eqref{eq:successrateTol} as the proportion of the successes from the $\nMC = 200$ runs.

%\ML{
\subsubsection{Illustrative Example}
In particular, the simulation for each pair $(\mathrm{SNR}, \nBW)$ yields 200 estimates per initial value strategy.
This is illustrated graphically in \figref{fig:single-sim} for the value-pair $(-1.1\unit{dB},48)$ of the system with $Q = 6 \unit{dB}$, where the obtained distances $\norm[2]{\model{\bullet} - \model{\true{}}}$ are shown for the different strategies, and sorted by an ascending norm.
This effectively shows an empirical cumulative distribution function of the distance measure $\norm[2]{\model{\bullet} - \model{\true{}}}$ as sampled by the Monte Carlo algorithm.%}
 
%\JL{One observes:}
\subsubsection{Pertinent Observations}
With reference to \figref{fig:single-sim}, the following observations are worth noting: 
%\EG{
\begin{itemize}
\item The actual parametric estimates, based on the different initial estimates, have distinct behaviors with respect to their distance from $\model{\true{}}$.
Two major classifications can be made:
\begin{enumerate}
  \item `good' estimates which have $\norm[2]{\model{\bullet} - \model{\true{}}} < \absoluteTolerance \approx 6 \cdot 10^{-5}$,
  \item `poor' estimates which are much further from $\model{\true{}}$.  This is caused by the local optima.
\end{enumerate}
\item
The obvious jump of the observed distances of the final parametric estimates shows that both classes can be separated reliably.
The index at which this jump occurs is a direct (visual) indication of the success rate $\successRate$ of the corresponding strategy to obtain initial values.
This indicates $\frac{147}{200} \approx 74\%$ success for the existing methods, $\frac{189}{200} \approx 95\%$ for the truncation method and $100\%$ for RFIR in \figref{fig:single-sim}.
\end{itemize}
%}

\begin{figure}
  \centering
  \setlength{\figurewidth}{0.8\columnwidth}
  \setlength{\figureheight}{0.6\figurewidth}
  \input{\thisDir/figs/MC-SNR1.1dB-NBW36-Q6dB.tikz}
 \caption[Model error for different initialization schemes on simulations.]{The distance $\|\model{\bullet} - \hat{G}_0 \|_2$  between the different estimates ($\model{exist}$~\legref{leg:dist-G-exist}, $\model{trunc}$~\legref{leg:dist-G-trunc} and $\model{RFIR}$~\legref{leg:dist-G-RFIR} ) and the `best theoretical' estimates ($\model{0}$) shows that the smoothers help the estimate to converge to $\model{0}$.
 The same measure is shown for the initial values $\model[init]{RFIR}$ \legref{leg:dist-G-RFIR-init} and $\model[init]{trunc}$ \legref{leg:dist-G-trunc-init}.
 $\|{G}_{0} - \hat{G}_0\|_2$\legref{leg:dist-G0} shows how far the true model and `best theoretical' estimates are apart to put the other distances into perspective. }
  \label{fig:single-sim}
\end{figure}

%\subsection{Improvement w.r.t. existing techniques}%
\subsection{Improvement Over Existing Techniques}

In \figref{fig:successRateVS_SNR36N3dB}, the success rate (and its $95\%$ confidence interval $\mathrm{CI}$) obtained from the Monte Carlo simulations is shown to compare the proposed method with previously existing approaches.
Note that the empirical count of successes $n_{\mathrm{success}}$ out of the $\nMC$ total observations is binomially distributed with success rate $\successRate$.
The computation of confidence bounds of such a variable is not obvious due to the discrete nature of the variable: $n_{\mathrm{success}}$ can only attain a discrete set of values: $\Set{0,1,\ldots, \nMC}$ whereas the true success rate $\successRate$ is real-valued (but limited to the interval $[0,1]$).
The inherent discreteness of $\hat{\successRate} \isdef n_{\mathrm{success}}/\nMC$ and the difficulties this presents has sparked a fair amount of research to compute confidence bounds~\citep{Barnard1947Significance,Mato1997,Ross2003,Clopper1934}.
A simple way to deal with this problem, is to make use of the central limit theorem which states that $n_{\mathrm{success}}/\nMC$ is approximately normally distributed when $\nMC \to \infty$.
In doing so, one e.g. obtains the Wald confidence bounds~\citep{Ross2003}:
\begin{equation}
\mathrm{CI}_{\mathrm{Wald}} \isdef \hat{\successRate} \pm z_{1-\alpha/2} \sqrt{\hat{\successRate} (1-\hat{\successRate}/\nMC)}
\end{equation}
with $\alpha = 1 - 0.95$ for $95\%$ confidence bounds and $z_{1-\alpha/2}$ is the $1-\alpha/2$ quantile of a standard normal distribution, i.e. $z_{\beta} \isdef \mathrm{CDF}_{\NormalDistribution}^{-1}(\beta)$
which requires inversion of the \gls{CDF} of a normal distribution.
However, such an approximation is overly optimistic when $n_{\mathrm{success}}$ approaches the boundaries of its domain (i.e. when $\successRate \approx 0$ or $\successRate \approx 1$) since normal confidence regions are always symmetrical whereas the actual success rate is inherently bounded as $0 \leq \successRate \leq 1$~\citep{Ross2003}.
An alternative method that does not approximate the binomial distribution by a normal one, is the Clopper-Pearson method~\citep{Clopper1934}.
In particular, this method relies upon the exact binomial distribution, which is why the method is often quoted as the `exact' method.
In particular, the $(1-\alpha)$  confidence bounds on $\successRate$ are given by~\citep{Clopper1934}
\begin{align}\label{eq:initvals:Binomial:CI}
 \mathrm{CI}_{\mathrm{ClopperPearson}}  & \isdef \left[ \underline{\successRate}, \overline{\successRate} \right]\\
 \underline{\successRate} &\isdef 
  \mathrm{CDF}_B^{-1}(\phantom{1-\;}\alpha/2; n_{\mathrm{success}}, \nMC - n_{\mathrm{success}} + 1)\\
  \overline{\successRate} &\isdef
  \mathrm{CDF}_B^{-1}(1-\alpha/2; n_{\mathrm{success}} + 1, \nMC - n_{\mathrm{success}})
\end{align}
where $\mathrm{CDF}_B^{-1}(\alpha; n,m)$ denotes the inverse \gls{CDF} of a $\mathrm{Beta}(n,m)$ distribution~\citep{EncyclopediaOfMathematics}.
This is known to yield somewhat conservative bounds, especially if only failures or successes are observed~\citep{Ross2003}.

In this chapter, the Clopper-Pearson method---as implemented in \MATLAB's \code{binofit}---is used whenever confidence bounds are shown.
Consequently, the improvements observed in \figref{fig:successRateVS_SNR36N3dB} underestimate the actual improvement slightly due to the conservatism in these bounds.
However, since there is often a clear separation between the different techniques, no efforts have been made to use confidence interval estimators that offer less conservative results.

By aggregating the results for the different simulations and retaining the success rate $\successRate$ only, a clearer view of the performance of the different methods is obtained.

The success rates of $\model{exist}$, $\model{trunc}$ and $\model{RFIR}$ are depicted in  \figref{fig:successRateVS_SNR36N3dB} for two different numbers of sample points within the $3\unit{dB}$ bandwidth, and for a range of SNR values. A close scrutiny of  \figref{fig:successRateVS_SNR36N3dB} reveals the following observations: \begin{itemize}
\item The success rates increase with increasing SNR values, as expected.
\item For very low SNR values (below $0\unit{dB}$), $\model{exist}$ and $\model{trunc}$ are unreliable, whereas $\model{RFIR}$ is reliably successful. 
\item For relatively high SNR ($20\unit{dB}$), all three estimators perform equally well.
\item For moderate SNR values, the success rate of $\model{trunc}$ lies above that of $\model{exist}$.
\item The RFIR-based estimate exhibits a success rate of, at least, $97\%$ for all studied conditions. 
This clearly indicates that regularization makes it possible to obtain far more reliable initial estimates than both the LPM-Truncation-based ones and the existing ones. 
This is an important conclusion.
\end{itemize}
%}

%\JL{An important conclusion can be drawn from the last observation, in the range of the SNR where the success rate almost reaches 100\%. Namely, it tells us to what extent the estimator $\model{trunc}$ allows the SNR to be decreased before the estimator gets a too high fail rate. In other words, it shows that $\model{trunc}$ is more reliable at lower SNRs than $\model{existing}$.}
%\JL{
As far as $\model{trunc}$ and $\model{exist}$ are concerned, the observations on \figref{fig:successRateVS_SNR36N3dB} clearly reveal the extent to which the estimator $\model{trunc}$ allows for the SNR to be decreased before the estimator attains too high a fail rate. 
In other words, it shows that, at low SNR values $\model{trunc}$ is more reliable than $\model{exist}$. 

%\comment{JL: do we have the numerical results to add a remark like: At an SNR of xdB, the respective success rates of $\model{trunc}$ and $\model{existing}$ are $90\%$ and $95\%$. This means that, for that SNR, chances of failure have been reduced by a factor of 2!
%}
%\ML{Yea, shown below!}
%\EG{
  \figref{fig:successRateVS_SNR36N3dB} shows that, typically, for the system with $Q=6\unit{dB}$ when $\nBW=48$ and $-1.1 \unit{dB}$ \gls{SNR}, the existing initial values will fail to deliver a good transfer function estimate for one in four trials ($\approx 74\%$ success rate).
However, by using the truncated \gls{LPM}'s initial estimates, the number of failures is reduced fivefold ($\approx 95\%$ success rate) over the existing initial estimates.
Moreover, the \gls{RFIR} initial values lead to poor estimates in less than $2\%$ ($>$ $98\%$ success rate) of the cases, since none were observed in the Monte Carlo simulation.

\paragraph*{Extension of the SNR range for $\model{trunc}$ over $\model{exist}$}
A close inspection of \figref{fig:successRateVS_SNR36N3dB} reveals that the \gls{SNR} range associated with an acceptable success rate (e.g. $\successRate \geqslant 90\%$) is improved for $\model{trunc}$ over $\model{exist}$. The range of improvement is approximately 5 dB where the success rate is above $90\%$. 
This result is very useful for a user working with noisy data.

\begin{figure}
  \centering
  \setlength{\figurewidth}{0.85\columnwidth}
  \setlength{\figureheight}{0.68\figurewidth}
  \input{\thisDir/figs/successRates.tikz}
 \caption[Simulated success rate of the different initialization schemes for varying \glsentryshort{SNR}.]{The success rate $\successRate$  obtained using the smoothers, i.e. $\model{RFIR}$~\legref{leg:success-RFIR} and $\model{trunc}$~\legref{leg:success-LPMTrunc}, are significantly higher than for the existing methods $\model{exist}$~\legref{leg:success-existing} in most of the studied range of \glspl{SNR}, number of samples and for both test systems. The $95\%$ confidence intervals~\eqref{eq:initvals:Binomial:CI} are indicated by bars.}
  \label{fig:successRateVS_SNR36N3dB}
\end{figure}

\begin{figure}
  \centering
  \setlength{\figurewidth}{0.66\columnwidth}
  \setlength{\figureheight}{0.68\figurewidth}
  \input{\thisDir/figs/RMSEvs_SNR36N3dB-ripple6.tikz}
 \caption[Simulated model \glsentryshort{RMSE} compared to rule-of-thumb.]{The accordance between the observed \gls{RMSE} of $\model{\true{}}$~\legref{leg:RMSE:delta:observed}(with $\pm2\sigma$ interval) and the rule-of-thumb~\eqref{eq:heur-RMSE}\legref{leg:RMSE:rule-of-thumb} shows how well $\model{\true{}}$ approximates the true system $\true{G}$.
 In the bottom plot, the difference between both is shown.
 Consequently, it makes sense to examine the behavior of the models in terms of $\model{\true}$ as long as this RMSE meets the user's requirements.}
  \label{fig:RMSE}
\end{figure}

\paragraph*{Remark about the model quality}
In principle, convergence of the estimate $\model{\bullet}$ to the `best' estimate $\model{\true{}}$ does not imply that $\model{\bullet}$ will be suitable for a specific purpose as the estimate $\model{\true{}}$ itself might be ill-suited.
A straightforward tool to analyze the error associated with $\model{\true{}}$ is to examine its relative \gls{RMS} error, with respect to the true system $\true{G}$, over different realizations of the experiment.
In~\citep{Ljung1999}, a rule-of-thumb is given that describes the relationship between the \gls{SNR} of the signals and the quality of the estimated parametric model.
In this context this heuristic boils down to: 
\begin{equation}
    \RMSE(\model{\true{}}) \approx \sqrt{\frac{n_\theta}{N}} \frac{\norm[2]{\true{G}}}{\SNR} 
    \label{eq:heur-RMSE}
\end{equation}
where $n_{\theta}=5$ is the number of estimated parameters in this case.
In \figref{fig:RMSE}, the empirical $\RMSE(\model{\true{}})$ over the different Monte Carlo runs is displayed against this rule-of-thumb.
It can be seen that these runs align almost perfectly, which shows that this rule-of-thumb can be used to approximate the \gls{RMSE} of the parametric estimate.
When the \gls{RMSE} is then divided by $\norm[2]{\true{G}}$, this graph essentially shows the anticipated relative error on the transfer function and, hence, gives an indication on its usability.

\section{Experimental Results}
\label{sec:initial-values:ExpMeas}
Measurements were performed on an electrical filter to assess the performance of the initial value generating methods in a physical setting.

\subsection{Experimental Setup}
The \BK{} 1613 Octave Filter Set consists of sixth-order Chebyshev band-pass filters~\citep{datasheet_bk1613}, from which we only examined the filter with a center frequency of $4\unit{kHz}$.

\begin{figure}
  \centering
  \includegraphics[width=0.6\columnwidth]{\thisDir/figs/measurement.pdf}
  \caption[Measurement schematic of \BK\ 1613 filter.]{Schematic representation of the measurement set-up for the \BK\ 1613 filter. The \glsentryfirst{AWG} and \glsentryfirst{DAQ} hardware share the same clock and are thus synchronized. 
  Blue arrows indicate coax cables. 
  At the output of the bandpass filter, a noise generator is added that buffers the incoming signal using a TL071 opamp and adds white noise before passing the signal to the DAQ.} 
  \label{fig:measurementSetup}
\end{figure}


To measure the transfer function, the \BK{} 1613 Filter was excited by a signal $r(t)$ and both its input $u(t)$ and output $y(t)$ were measured as shown in \figref{fig:measurementSetup}.
The output $y(t)$, however, was disturbed by a noise generator that added white noise over the frequency range $[\mathrm{DC}, 20\unit{kHz}]$.
The excitation signal $r(t)$ was white random noise with a standard deviation $\sigma_r = 0.25 \unit{V}$, consisting of $N_S = 8\,192$ samples, and sampled at $92 \unit{kHz}$.
The same noise sequence was repeated $N_R = 100$ times in succession, such that a non-parametric estimate of the noise could be obtained and the performance of the methods could be gauged over these different repetitions.
To distinguish the different repetitions, we denote the $r^{\text{th}}$ repetition of the $u$ signal as $u^{[r]}(t)$ (and similarly for $y(t)$).
The signal generation and acquisition was by means of a \gls{NI} Elvis II, using the respective \code{AO} and \code{AI} pins on the breadboard, which were wired to BNC connectors.
Although acquisition and generation were synchronized, there is a small delay $\tau_{\mathrm{MUX}} \approx 9\unit{\mu s}$ between the acquisition of the input $u(t)$ and the output $y(t)$ due to the hardware architecture of the \gls{NI} Elvis~II.
Particularly, the involved channels are captured by means of a single \gls{ADC} which is preceded by a multiplexer to select the active channel.
This obviously introduces a slight delay between the acquisition of a sample of input and output channels that is not part of system dynamics of the \BK{} filter, but rather of the experimental set-up.
As such, the output spectrum $Y(\omega)$ was multiplied by $\exp\left(-j\omega\tau_{\mathrm{MUX}} \right)$ such that this inter-channel acquisition delay of the \gls{NI} Elvis is compensated; the time-domain counterpart $y(t)$ is obtained using the \gls{IDFT}.

\begin{figure}
  \centering
  \setlength{\figurewidth}{0.75\columnwidth}
  \setlength{\figureheight}{0.68\figurewidth}
  \input{\thisDir/figs/bode-bk1613.tikz}
  \caption[\BK{} 1613 filter transfer function]{Transfer function of the considered \BK{} 1613 filter.
  The empirical transfer function estimates $Y^{[r]}(\omega)/U^{[r]}(\omega)$~\legref{leg:bk1613:ETFE} and their average $\tilde{Y}(\omega)/\tilde{U}(\omega)$~\legref{leg:bk1613:meanETFE} obtained from the Elvis measurements are shown together with the estimated reference model $G_{\VXI}$~\legref{leg:bk1613:vxi}.} 
  \label{fig:bk1613}
\end{figure}


\subsection{Identification Procedure}
The repeated nature of the experiment makes it possible to estimate the noise level from the signals non-parametrically.
The mean signal from the input $u$ is of the form:
\begin{equation}
  \tilde{u}(t) = \frac{1}{N_R} \sum_{r=1}^{N_R} u^{[r]}(t)
\end{equation}
Thus, the reduced noise influence and the approximate noise co-variances are, respectively:
\begin{align}
  \hat\sigma_{u}^2(t) &= \frac{1}{N_R - 1} 
                    \sum_{r=1}^{N_R} 
                    \left( u^{[r]}(t) - \tilde{u}(t) \right)^2 \\
%and the noise co-variances are approximately
  \hat\sigma_{yu}(t) &= \frac{1}{N_R - 1} 
                    \sum_{r=1}^{N_R} 
                    \left( y^{[r]}(t) - \tilde{y}(t) \right)
                    \overline{\left( u^{[r]}(t) - \tilde{u}(t) \right)}
  \label{eq:variancePeriodic}            
\end{align}
 
Similar calculations apply to $y(t)$ and as such, $\hat\sigma_u(t)$, $\hat\sigma_y(t)$ and $\hat\sigma_{yu}(t)$ can be estimated.
Their frequency domain counterparts $\tilde{U}(\omega)$ and $\tilde{Y}(\omega)$ are obtained by using the DFT.
The resulting empirical transfer function estimate $Y^{[r]}(\omega)/U^{[r]}(\omega)$ and its periodic average $\tilde{Y}/\tilde{U}$ are shown in \figref{fig:bk1613}.
The noise covariances $\hat\sigma^2_{U}(\omega)$, $\hat\sigma^2_{Y}(\omega)$ and  $\hat\sigma_{YU}(\omega)$ are calculated as the sample covariance, akin to equation \eqref{eq:variancePeriodic}, and their values are shown in \figref{fig:SpectraMeasurement}.
Note that the SNR at the output $\mathrm{SNR}_{y} \approx 14 \unit{dB}$ is much smaller than at the input $\mathrm{SNR}_{u} \approx 50 \unit{dB}$.

\begin{figure}
  \centering
  \setlength{\figurewidth}{0.75\columnwidth}
  \setlength{\figureheight}{0.68\figurewidth}
  \input{\thisDir/figs/elvis-spectra.tikz}
  \caption[Measured input/output spectra of \BK{} filter.]{Average input $\tilde{U}(\omega)$ and output $\tilde{Y}(\omega)$ spectra \legref[2]{leg:SpectraMeasurement:U:mean} measured using the Elvis and the noise levels $\hat\sigma_U$ and $\hat\sigma_Y$  \legref[2]{leg:SpectraMeasurement:U:noise}.}
  \label{fig:SpectraMeasurement}
\end{figure}

For each measurement repetition, the signals $u^{[r]}(t)$, $y^{[r]}(t)$ and the variances $\sigma_U^2(\omega)$, $\sigma_Y^2(\omega)$ are used in the maximum likelihood cost function given by equation \eqref{eq:MLEcf}.
The model order was chosen according to the specifications of the sixth-order (Chebyshev) bandpass filter \citep{datasheet_bk1613}.
Since such a bandpass filter is of sixth degree and requires a relative degree of 3 to produce a $60 \unit{dB/decade}$ slope at high frequencies, this means that the transfer function has a numerator of third order, a denominator of sixth order and transient contribution of a fifth degree (i.e. model order: $3/6+5$).
This results in a transfer function of the form:
\begin{equation}
  \model{\bullet}(s,\theta) = 
  \frac{\Sum_{i=0}^3 b_i s^i}{\Sum_{i=0}^6 a_i s^i}
\end{equation}
which is typical of a sixth-order band-pass filter.
By processing the different repetitions, a parametric fit per initialization method corresponding to the appropriate branch in \figref{fig:flowgraph}, and per repetition can be obtained. 
\begin{remark}
Fitting the data with models of increased order (e.g. $4/6+5$) has also been attemped, but those models did not yield significant improvements.
\end{remark}


The following equation is constructed from the final estimates for each experiment; it gives an insight into the combined contribution to the `best' estimate from all the different initialization strategies, \emph{viz}:

\begin{equation}\label{eq:selectBest}
  \model{best} = 
    \Arg_{\hat{G}} 
    \min 
    \left\{ 
      V(\model{exist}),
      V(\model{trunc}),
      V(\model{RFIR})
    \right\}
\end{equation}
where $V(\hat{G})$ corresponds to the cost function in equation \eqref{eq:MLEcf} in the parametric estimates of $\hat{G}$.
This is similar to the approach followed in~\citep{FDIDENT} to combine different initial estimates.

Alternatively, one can define the best model ($\model{best}$) and the second best model ($\model{2nd}$) as the models that comply to the inequalty
$
  \costFunc{}\left(\model{best}\right) < 
  \costFunc{}\left( \model{2nd} \right) < 
  \ldots
$
where $\model{best} \neq \model{2nd}$.

\subsection{Reference Model Measurements}

%\JL{
Since the true model $\true{G}$ is not known for real-life systems, a practically viable reference model is needed.
Additional measurements were performed using a \gls{VXI} measurement setup, which allowed for a signal-to-noise ratio of more than $60\unit{dB}$. 
Virtually noiseless, these measurements provided a very high quality model of the system, denoted as $G_\VXI$, and used as a reference model. 
The \gls{VXI} measurement setup is summarized as follows.
\begin{itemize}
  \item Signal Generator card: \gls{VXI} HP E1445A.
  \item Acquisition cards: \gls{VXI} HP E1430A.
  \item Sampling frequency: $f_\mathrm{s} = 156\,250 \unit{Hz}$.
  \item A total of $558$ frequency bins were used for the estimation, in the excited frequency band $[0.1,20] \unit{kHz}$, with a frequency resolution of $35.7\unit{Hz}$, giving a measurement time of $28\unit{ms}$. The excitation signal was band-limited periodic noise whose \gls{RMS} value was $100\unit{mV}$.
  \item The input and output signals were buffered and anti-alias filtered.
\end{itemize}
This yielded the parametric model $G_\VXI$ (shown in \figref{fig:bk1613}) with a relative error of less than $0.3\%$ in the pass-band with respect to the measured \gls{FRF}.  
Denote $\model{VXI}$ to be the parametric estimate obtained using $G_{\VXI}$ as an initial estimate. Furthermore, $G_\VXI$ was used to play the role of $\true{G}$ from the previous section.

\subsection{Model Estimation}
  The measurements on the NI Elvis II indicate that the high-quality starting value $G_{\VXI}$ led to low cost function values as shown in \figref{fig:costMeasurements} and \tabref{tbl:costMeasurements}.
  The existing methods exhibit a high spread and a high median cost function, showing that a good estimate is obtained only in about $25\%$ of the cases.
  The truncation method provides better estimates in many cases, but still suffers from a high variability.
  On the other hand, the \gls{RFIR}-based initial values have both a low median cost function and spread, and thus provide better fits in almost all cases.
  Obviously, $\model{best}$ has the lowest cost function values of all methods.
  The similarity of the results for $\model{RFIR}$ and $\model{best}$ suggests that the \gls{RFIR} provides the best estimate in most of the cases.
  This can indeed be confirmed by inspecting the different estimates per repetition of the experiment.

\begin{remark}
  In the simulations (e.g. \figref{fig:single-sim}), a $60\unit{dB}$ difference between `good' and `bad' estimates was observed.
  Such a large gap is not observed in the measurements (\figref{fig:costMeasurements} and \tabref{tbl:costMeasurements}).
  Hence, defining a success rate based on a threshold tolerance would be very sensitive to the specific value of the threshold and hence unreliable.
  Instead, the statistical location and dispersion are inspected to assess the relative performance of each method.
  Practically, the median is used as a measure of location and the \gls{IQR} is used to inspect the spread as these are far more robust to outliers than e.g. the sample mean and variance.
  These measures also have an easy interpretation: the median ($50\%$ percentile) indicates the cost function value that $50\%$ of the repetitions attain.
  On the other hand, the \gls{IQR} ($25\%$ through $75\%$ percentile) contains  exactly half of the observations.
\end{remark}

\begin{figure}[p]
  \centering
  \setlength{\figurewidth}{0.85\columnwidth}
  \setlength{\figureheight}{0.68\figurewidth}
  \setlength{\figurewidth}{0.75\columnwidth}
  \input{\thisDir/figs/CostFunctionsMLE-measurement.tikz}
  \caption[Cost function values over the different measurements.]{Cost function values $V(\theta)$ obtained during the different realizations of the measurement.
  The bottom plot shows a linear zoom of the top plot.
  For each method, the inter-quartile range~\legref{leg:costMeasurements:best:iqr}, median~\legref{leg:costMeasurements:best:median} and individual values~\legref{leg:costMeasurements:best:data} are shown.
  This implies that a lower (local) minimum of the cost function can be attained using these smoothing techniques.}
  \label{fig:costMeasurements}
\end{figure}

\begin{table}[p]
  \centering
  \caption{Observed percentiles of the cost function $V(\model{\bullet}$).}
  \input{\thisDir/tables/meas-cost-quantiles.tbl.tex}
  \label{tbl:costMeasurements}
\end{table}



\subsection{Model Validation}
\subsubsection{Cost Function Limitations}
In the previous section, the cost function was studied to determine the effectiveness of the starting values.
However, inspecting the cost function $V(\theta)$ only accounts for how well an estimated model fits the measured data, which may be misleading.
For an example, overfitting a model may result in the absorption of both the systematic behavior and the noise into the model. 
Consequently, an arbitrarily small cost function may ensue although the estimated model may be virtually useless to predict the system behavior.

\subsubsection{Validation Criterion}
To objectively assess the quality of an estimated model, a different criterion than the cost function is inspected.
To this end, the model is validated using the 2-norm (or distance) on the model error:
\begin{equation}
  \validationDistance{\bullet} 
  \isdef 
  \norm[2]{\model{\bullet} - G_{\VXI}}
  \text{.}
  \label{eq:measurementCriterion}
\end{equation} 
This criterion indicates how well the obtained estimates $\model{\bullet}$ are able to describe the transfer function of the bandpass filter as observed in the validation measurement on the \gls{VXI}.

\subsubsection{Validation Performance}
The observed median and \gls{IQR} of the distances in \figref{fig:validationMeasurements} and \tabref{tbl:validationMeasurements} have a similar qualitative interpretation as the cost function on the estimation data.
The existing methods provide good estimates in only $25\%$ of the cases.
The truncation method provides a considerable improvement but still suffers from $25\%$ poor estimates.
Compared to the existing \gls{BTLS} and \gls{GTLS} techniques, the \gls{RFIR} and hence also $\model{best}$ entail an overall reduction in the observed distance by a factor $8$, in most cases. 
On the other hand, the reference $\model{VXI}$ shows the best global performance. 
This indicates that the proposed methods do no converge to the same local optimum.
Nevertheless, the proposed methods improve the model quality by almost an order of magnitude.

As the criterion in equation~\eqref{eq:measurementCriterion} no longer depends on the cost function, the initial estimates can also be investigated.
The difference between the distance of $\model[init]{\bullet}$ and $\model{\bullet}$ indicates how much the final ML estimate from the raw data, in each respective branch of \figref{fig:flowgraph}, improves over the initial estimate.
Remarkably, on average, the final ML estimation provides only a marginal improvement for the \gls{RFIR}. 
However, this final step reduces the spread and hence yields a more reliable estimate.
E.g. note in \tabref{tbl:validationMeasurements} that this step reduces the worst-case distance from $18.21$ to $4.55$.


\begin{figure}[p]
  \centering
  \setlength{\figurewidth}{0.85\columnwidth}
  \setlength{\figureheight}{0.68\figurewidth}
  \setlength{\figurewidth}{0.75\columnwidth}
  \input{\thisDir/figs/meas-validation.tikz}
  \caption[Validation cost of the different measurements.]{Validation of the measured models. 
  For each method, the distance \eqref{eq:measurementCriterion} between the estimates and $G_{\mathrm{VXI}}$ is shown~\legref{leg:validationMeasurements:best:data} together with the median~\legref{leg:validationMeasurements:best:median} and inter-quartile range~\legref{leg:validationMeasurements:best:iqr}.
  $\norm[2]{G_{\VXI}}$\legref{leg:validationMeasurements:H2Norm} is shown as a reference.
  The bottom plot shows a linear zoom of the top plot.
  The proposed methods yield models that are closer to $\model{VXI}$ than the existing $\model{exist}$.
  The results are in line with the values of the cost function in \figref{fig:costMeasurements}.}
  \label{fig:validationMeasurements}
\end{figure}
\begin{table}[p]
  \centering
  \caption{Observed percentiles of the validation distance $\norm[2]{\model{\bullet}-G_{\VXI}}$.}
  \input{\thisDir/tables/meas-validation-quantiles.tbl.tex}
\label{tbl:validationMeasurements}
\end{table}

\section{Consequences of Selecting the `Best' Model}
To determine how important it is to retain the `best' model based on the cost function values, we shall inspect how much worse (or better) the second best model $\model{2nd}$ performs when $\model{best}$ is \emph{not} selected.
To do so, we inspect the performance by means of the cost function (used during estimation) and by means of the validation distance.
The datasets used in this analysis are those from the measurements, but similar results can be obtained from the other data sets.

In \figref{fig:overview} we can compare $\model{2nd}$ and $\model{best}$.
By inspecting the different estimates for  each of the repeated experiments (\figref{fig:overview}), it can easily be seen that choosing $\model{RFIR}$ while it is not $\model{best}$ only leads to a very modest performance degradation.
In \figref{fig:init:histogramEnhancement}, the different methods are compared by subtracting the performance of the $\model{best}$ from the performance of the respective methods.
As such, each column in the figure indicates the performance of this method when it is not the `best'.
Obviously, when we consider the cost function used during estimation (left subfigure), we can only degrade the performance by construction of $\model{best}$.
For the validation data, however, this is no longer guaranteed as can be seen in the right subplot.
On average, there is very little performance that can be gained from not using $\model{best}$, however, for two or three data points, there is a considerable improvement.
From that figure it can also be seen that there is little performance to lose from choosing $\model{RFIR}$ over $\model{best}$ when RFIR is not the `best' method.
The outcome is less favorable for the alternative methods.
For $\model{exist}$ it can be seen that selecting those instead of $\model{best}$  degrades the validation performance by $10$ or even more in $75\%$ of the cases.
The situation is already less severe for $\model{trunc}$ (in $75\%$ of the cases, the degradation is larger than $0.5$).

\begin{figure}
  \centering
  \setlength{\figurewidth}{0.85\columnwidth}
  \setlength{\figureheight}{0.68\figurewidth}
  \input{\thisDir/figs/overview-cost-val.tikz}
  \caption[$\costFunc{\bullet}$ and $\validationDistance{\bullet}$ for each repeated measurement.]{Cost function $V(\model{\bullet})$ and validation distance of the model estimated in each repetition of the measurement.
  Based on the cost function, $\model{RFIR}$~\legref{leg:RFIR} is not always the best estimate $\model{best}$~\legref{leg:best}.
  Especially in the validation plot (bottom), $\model{RFIR}$ performs (almost) as well or even better than $\model{exist}$~\legref{leg:exist} and $\model{trunc}$~\legref{leg:trunc}.
  Both latter methods often produce models that perform poorly compared to $\norm[2]{G_{\VXI} }$~\legref{leg:reference} and $\model{VXI}$~\legref{leg:VXI}.
  This means that in our limited experimental study, the performance degradation of choosing \glsentryshort{RFIR} to produce initial values over the studied alternatives is small.}
  \label{fig:overview}
\end{figure}

\begin{figure}
  \centering
  % \ref{leg:init:secondBest}
  \setlength{\figurewidth}{0.75\columnwidth}
  \setlength{\figureheight}{0.60\figurewidth}
  \input{\thisDir/figs/special-histogram.tikz}
  \caption[Performance degradation/enhancement for selecting the second best model.]{
  Performance degradation/enhancement ($X_{\bullet}-X_{\mathrm{best}}$) for choosing a given method $\bullet$ instead of the `best' method for the measurement example in this chapter.
  The markers show individual observations and the boxes show the \gls{IQR}.
  The dashed lines are the minimum, median and maximum of $X_{\bullet}$ to give a sense of scale.
  On average there is little to gain or lose from using $\model{RFIR}$ instead of $\model{best}$.
  For $\model{exist}$ and $\model{trunc}$, the situation is a lot less favorable.
  }
  \label{fig:init:histogramEnhancement}
\end{figure}

\section{Remark on the Generality}
\label{sec:initial-values:Generality}
In the previous sections, the usability of the smoothers to produce initial values has been studied on very specific examples.
In this section, an attempt will be made to illustrate the usefulness of these smoothers for the generation of starting values for other systems.
However, due to the intricate relationship between the attraction regions in the cost function, the location of the actual system poles, the \gls{SNR} level and the choice of a particular excitation signal, we think it is intractable to construct rigid bounds on where the smoothers produce effective starting values.

\subsection{Limitations of the Smoothers}
On the one hand, an obvious limitation to the presented initialization techniques is that they share the limitations of the smoothing techniques: if the non-parametric estimate is a worse representation than the raw data (e.g. heavily biased), it is very unlikely that the initial estimate will outperform the existing estimates.
However, it is beyond the scope of this chapter to determine formally which particular smoother is optimal in some specific experimental circumstances.

In particular for \gls{RFIR}, a simulation study in~\citep{Chen2013} suggests that RFIR handles systems with model orders up to at least $30$, even for small datasets $N\leq 500$.
For \gls{LPM} (with or without time-truncation), no comparable studies are available to our knowledge, but the \gls{LPM} itself has been used successfully in diverse practical applications.

\subsection{Stress Test of the Smoothers}
To test the effectiveness of the initial estimates obtained from these particular smoothers, an extra set of $\nMC = 100$ Monte Carlo simulations were performed.
In particular, all combinations of
\begin{itemize}
  \item low-pass, high-pass, band-pass and band-stop 
  \item Chebyshev Type I, Chebyshev Type II, Elliptical and Butterworth
\end{itemize}
discrete-time filters~\citep{Zverev1967} of tenth degree generated by the \MATLAB code in \lstref{lst:initvals:stressSystems} are simulated.
Each of these filters $\true{G}$ have been normalized such that $\norm[2]{\true{G}} = 1$.
The low-pass and high-pass filters have a cross-over frequency of $\frac{\pi}{2} \unit{rad/s}$. 
The band-pass, respectively band-stop, filters have a passband, respectively stopband, in the frequency range$\left[ \frac{2\pi}{5}, \frac{3\pi}{5}\right] \unit{rad/s}$.
Note also that both the band-pass and band-stop filters have a McMillan degree of 20 as per the \MATLAB conventions.
See \tabref{tbl:init:stresstest} for an overview of the filters and  \figref{fig:bodeplots} for the corresponding bode plots.


\lstinputlisting[float,style=matlab,mathescape,basicstyle=\ttfamily\scriptsize,caption={Code to generate the systems of the stress tests.},label={lst:initvals:stressSystems}]{\thisDir/code/systemsForStressTest.m}


The input excitation and the disturbing output noise were $N=1\,024$ samples of white Gaussian noise such that an \gls{SNR} of $20 \unit{dB}$ was attained at the output.
Note that due to $\norm[2]{\true{G}}=1$, the validation distance $\norm[2]{\model{\bullet} - \true{G}}$ is exactly the relative \gls{RMS} estimation error of the transfer function.

\begin{table}
  \centering
  \caption{Overview of the test cases for the initialization stress test.}
  \input{\thisDir/tables/stresstest-cases.tbl.tex}
\label{tbl:init:stresstest}
\end{table}

\subsection{Observations}
The transfer functions are shown in \figref{fig:bodeplots} while the empirical cumulative validation distance is shown in \figref{fig:distancesStress}.
In \tabref{tbl:init:stresstest}, also the success rates per method are given when a tolerance $\absoluteTolerance = 0.02$ is used when success is determined as $D_{\bullet} = \norm[2]{\model{\bullet} - \true{G}} < \absoluteTolerance$.
This is equivalent to the relative criterion of success since $\norm[2]{\true{G}} = 1$ for all systems.

\begin{figure}[p]
  \setlength{\figurewidth}{0.85\columnwidth}
  \setlength{\figureheight}{0.68\figurewidth}
  \centering
  \input{\thisDir/figs/bodeplots.tikz}
  \caption[Bode plots of the stress test filters.]{Bode plots of the tested filters~\legref{leg:bode:true} in the stress test. 
  For each filter, two (randomly selected) instances of the parametric estimates $\model{\bullet}$ are shown per method.
  }
  \label{fig:bodeplots}
\end{figure}

\begin{figure}[p]
  \setlength{\figurewidth}{0.85\columnwidth}
  \setlength{\figureheight}{0.68\figurewidth}
  \centering
  \input{\thisDir/figs/distances.tikz}
  \caption[Empirical \glsentrytext{CDF} of $\validationDistance{\bullet}$ in the stress test.]{Empirical cumulative distribution function of the validation distance $D_{\bullet} = \norm[2]{\model{\bullet} - \true{G}}$ for the different tested systems (different numbered plots) and the different initial values (colors).
  Note that since $\norm[2]{\true{G}}=1$ is chosen, $D_{\bullet}$ immediately indicates the relative RMS error of the estimates.
  }
  \label{fig:distancesStress}
\end{figure}

A few remarks regarding these results are appropriate.
\begin{itemize}
  \item In many of the tested situations (cases 1,3,13--16), all methods yield a good model quality.
  \item In some situations (cases 8, 10, 12), the model quality is generally poor. 
  The fact that for cases 8 and 12, the `ideal' starting value \model{0} also provides poor models means the data is not informative enough to reasonably fit a good model.
  \item In all cases except 10 and 12, the \gls{RFIR} performed as well or better than the existing methods.
  \item In case 10, the model quality of the \gls{RFIR} is slightly worse than the already poor existing techniques.
  This is an underlying limitation of the \gls{RFIR} used: $n_g=200$ taps was used, however the true impulse response has not decayed significantly in that interval.
  Essentially, the particular \gls{RFIR} used introduces a significant bias in the non-parametric description of the filter and hence the obtained initial value is unreliable.
  \item The \gls{RFIR} performs (significantly) better than the existing methods in various cases (4--7, 9, 11).
  \item Since the `best' method \legref{leg:dist:modelBest} yields better models more often than a single method, e.g. in cases 2, 4 and 6, this illustrates that combining initialization schemes improves the model quality.
  Particularly, case 2 implies that \model{best} contains initial estimates of all different techniques.
  \item For all of the tested systems (except possibly for case 2), the truncated \gls{LPM} is not advisable over the existing methods.
\end{itemize}

In general, one can see from these simulations that \gls{RFIR} either performs as well as (or even better than) the existing techniques when a good estimate is obtained.
There are no cases where using the smoothing to obtain initial values worsens the obtained model quality when the candidate model with the lowest cost function value is used (as in \eqref{eq:selectBest}).
On the contrary, significant improvements were often achieved by including the initial values from the smoothed \gls{FRF} and by combining different strategies.

\section{Computational Effort}\label{sec:initvals:computation}
While improved initial values yield better models of an improved quality, their generation does require some computational effort.
Although the amount of available computing power has been steadily increasing over the last decades, it remains important to keep an eye on the computing effort required to estimate a model or, in this case, to generate the starting values required to estimate a model.
E.g. in the field of embedded processors, which has been attracting a lot of attention over the last few years leading to ``Internet of Things'', it remains an important factor since computing power and physical power consumption are still relatively scarce.

Here, we will discuss two aspects of the computational effort very briefly.
On the one hand, the computation time, as measured on a physical computer with a practical implementation of the algorithms, gives a rough idea of how these methods may perform in practice.
On the other hand, the asymptotic complexity of the different smoothers is investigated. 
While such asymptotics give little insight in practical running times, they are valuable tools to see how well (or poor) such methods scale up towards larger datasets.

\subsection{Practical Runtime}
In practical measurements of the computation time for any piece of software, one typically distinguishes between different kinds of `time'.
\begin{itemize}
  \item The wall-clock time $\wallclocktime$, sometimes called `real time`, is the time difference between the start and end of the program under test.
  \item The \glsentryshort{CPU} time $\cputime$, is the amount of time that the \glspl{CPU} actually spends executing the program under test.
\end{itemize}
This distinction is necessary for multi-tasking environments (such as modern computers): during the execution of the program under test, the \gls{CPU} may spend some time executing other programs in the background.
The latter obviously requires a small amount of wall-clock time, but it does not increase the \gls{CPU} time of the program:
\begin{equation}
  \wallclocktime = \cputime + t_{\mathrm{other\;processes}}
\end{equation}
for a single-core \gls{CPU}.

In summary, the $\cputime$ is an indication of the computational effort required to execute the algorithm, whereas $\wallclocktime$ indicates the amount of time a user has to wait for the program.
In this case $\cputime$ is hence the most relevant of both, since $\wallclocktime$ is also determined by what other programs the user is running at the same time.

Unfortunately, \MATLAB, like many other interpreted languages, does not provide any feature to measure $\cputime$ of a segment of code.
Instead, the typical \mcode{tic} and \mcode{toc} functions measure the wall-clock time.
To reduce the effect of other running programs and one-time actions (e.g. just-in-time compilation, caching, \ldots), it is a common practice~\citep{McKeeman2008} to repeatedly measure $\wallclocktime$ and retain the minimum (as an approximation for $\cputime$) and/or the median (to reduce the effect of other programs claiming the \gls{CPU} for extended amounts of time).

In this case, the \MATLAB function \mcode{timeit}~\citep{matlab:timeit} has been used to measure the timing of the different functions.
This function  reports the median wall-clock time and chooses the number of repetitions automatically.
The timings have been measured on an Early 2013 MacBook Pro Retina 15-inch with $2.7\unit{GHz}$ Intel Core i7 \gls{CPU} and $16 \unit{GB}$ \gls{RAM} running Mac OS X 10.11.3 and \MATLAB R2015b.
The recommendations from the white paper by \citet{McKeeman2008} have been followed during these measurements.

To measure the timing of the different methods, essentially the same settings were used as in \secref{sec:initial-values:Demo}: the systems from equations \eqref{eq:systemundertest} and \eqref{eq:systundertest-20dB} were simulated such that $\nBW \in \Set{36,48}$ and $\SNR = 0 \unit{dB}$.
For each of the branches in \figref{fig:flowgraph}, three different timings are recorded (when applicable):
\begin{itemize}
  \item $t_{\mathrm{smooth}}$ is the time it takes to perform the smoothing (all blocks before \gls{GTLS}/\gls{BTLS}),
  \item $t_{\mathrm{init}}$ is the time it takes to fit $\model[init]{\bullet}$, and
  \item $t_{\mathrm{final}}$ is the time it takes to fit $\model{\bullet}$.
\end{itemize}
The median timings as returned by \mcode{timeit} are reported in \tabref{tbl:init:timing}.

\begin{table}
  \centering
  \caption{Observed timing of the different estimation steps.}
  \input{\thisDir/tables/timings.tbl.tex}
\label{tbl:init:timing}
\end{table}

From the timings in \tabref{tbl:init:timing}, it can be seen that the smoothers require a considerable amount of time that overshadows the fitting time.
However, it should be noted that all these implementations rely on code that has not been optimized for performance.
As such it is not possible to draw conclusions about the performance one may expect from optimized implementations that one would use in a commercial toolbox.

In particular the \gls{RFIR} smoother takes an exorbitant amount of time.
The fact that for small problem sizes (top of the table) the runtime is only slightly shorter than for the larger problems (bottom of the table), suggests that there is a considerable fixed overhead in the implementation we used.
Particularly, the construction of the \gls{DCkernel} matrix happens to be the culprit for these long execution times.
The truncated \gls{LPM}, on the other hand, requires a more reasonable amount of time for the short data lengths.
For longer datasets, it appears that the \mcode{kron} function is one of the major culprits for the long runtimes of the \gls{LPM}.

\subsection{Asymptotic Runtime}
For the asymptotic runtime, we are mainly interested in how the runtime of the smoothers scale with the size of the dataset, i.e. the number of samples $N$, and the model complexity $n_{\theta}$ of the smoother.

% See http://math.stackexchange.com/questions/84495/computational-complexity-of-least-square-regression-operation

Overall, the time-truncated \gls{LPM} operates in $\bigO{N n_{\theta}^{3}}$.
First, the \gls{LPM} solves $\bigO{N}$ linear regression problems of small dimensions ($2\numel{W} + 1$ data points and a few degrees of freedom, i.e. $n_{\theta} \leq 2 \numel{W} + 1$ or $\bigO{\numel{W}} = \bigO{n_{\theta}}$), hence the runtime will be $\bigO{N n_{\theta}^3}$ since solving a linear regression problem with $C$ parameters and $D$ data points requires $\bigO{C^3  + D C^2}$ operations\footnote{See \url{http://math.stackexchange.com/questions/84495}}.
The truncation of the impulse response relies on linear regression which takes $\bigO{N}$ operations since only $3$ parameters are estimated during this step.
As such, carrying out the first $\bigO{N n_{\theta}^3}$ step and then the $\bigO{N}$ step, the whole procedure remains a $\bigO{N n_{\theta}^3}$ or, equivalently, $\bigO{N \numel{W}^3}$.

The \gls{RFIR} relies on fitting a \gls{FIR} filter with $n_{\theta} = n_g$ taps to $N$ datapoints.
Using the same logic as above, this requires $\bigO{N n_{g}^2 + n_g^3}$ operations.

The computational complexity  of both methods scales linearly in the length of the dataset.
However, since the required length $n_g$ of a \gls{FIR} filter is typically a lot more (e.g. $200$ in this chapter) than the number of local parameters (or bandwidth) of the \gls{LPM} (e.g. $\numel{W} = 3$), it can be seen that eventually the \gls{RFIR} method will scale less favorably for the model complexity of the smoother.
Intuitively, the local modeling methods benefit from their locality since that enables them to be flexible without a huge amount of parameters.

\subsection{Implementation Aspects}
This section presents some implications and recommendations for the implementation of  a system identification toolbox.

Whereas \gls{RFIR} is shown to provide reliable starting values, it remains advisable to have multiple initialization strategies available to improve the likelihood of attaining a good starting value.
This is also the approach that toolboxes such as~\citep{FDIDENT} and~\citep{TDIDENT} employ.
Luckily, trying out multiple initialization strategies is \emph{embarrassingly parallellizable}, i.e. one can easily try out a different strategy in parallel without incurring a lot of overhead in terms of wall-clock time.
As such, computing multiple starting values can happen without a significant increase in wall-clock time and consequently a sluggish user-experience.

%TODO: TM: maybe look into power consumption aspects?

\begin{guideline}[Try regularization to improve convergence]
\label{guide:initvals:try-regularization}
Regularized estimators, such as \gls{RFIR}, sometimes provide better initial estimates than the `true' model parameters.
\end{guideline}

\begin{guideline}[Try different initial values for non-convex optimization]
\label{guide:initvals:try-many-initial-values}
Trying different initial values is quite inexpensive, but the quality of the final model may improve by several orders of magnitude if a local minimum can be avoided.
As such, using multiple initial values, especially ones that have been derived with good judgment, pays off.
\end{guideline}

\section{Conclusion}
\label{sec:initial-values:Conclusion}
The simulations have demonstrated that use of a smoothed non-parametric estimate of the \gls{FRF} can improve the success rate of minimizing the \gls{ML} cost function for the estimation of the transfer functions of \gls{LTI} systems, subjected to noisy signals. Specifically, two smoothing methods were used and compared: 1) the truncated \gls{LPM} method, and 2) the \gls{RFIR} method. The simulation results clearly show that the \gls{RFIR} method is superior to the truncated \gls{LPM} method and the existing \gls{BTLS} and \gls{GTLS} methods.

The usefulness of the initial values obtained via the proposed smoothing techniques was confirmed on a measurement of a band-pass filter in a noisy environment.
In most cases, the proposed initial values in the example made it possible to reduce the cost function by a factor two compared to existing methods.
Moreover, the obtained models were validated against a high-quality measurement where the \gls{RMS} error on the transfer function could be reduced by a factor of eight for most cases, due to the improved initial values.

Thus, the work in this chapter has demonstrated the effectiveness of the studied \gls{FRF} smoothing techniques in enhancing the initial values.
Consequently, the quality of parametric estimates can be increased considerably by using non-parametric \gls{FRF} models to initialize the non-convex optimization problem of fitting a rational transfer function model.
Hence, the ease-of-use of parametric model fitting can be increased significantly by having high-quality non-parametric \gls{FRF} models.
This comes at a limited cost for the end-user: in principle these smoothers can be tried without any additional intervention by the user.
The only disadvantage is the additional computational effort required and hence also the increase in wall-clock time to obtain a parametric estimate.
However, thanks to the recent trend of parallel computing and the fact that this problem is embarrassingly parallel, we expect that increases in wall-clock time can be kept very modest if performance-tuned implementations are used.
